{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchinfo import summary\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/plantvillage/\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data_dir = './data/plantvillage/'\n",
    "print(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Classes: 38\n",
      "Data set class names: \n",
      "['Apple___Apple_scab', 'Apple___Black_rot', 'Apple___Cedar_apple_rust', 'Apple___healthy', 'Blueberry___healthy', 'Cherry_(including_sour)___Powdery_mildew', 'Cherry_(including_sour)___healthy', 'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot', 'Corn_(maize)___Common_rust_', 'Corn_(maize)___Northern_Leaf_Blight', 'Corn_(maize)___healthy', 'Grape___Black_rot', 'Grape___Esca_(Black_Measles)', 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)', 'Grape___healthy', 'Orange___Haunglongbing_(Citrus_greening)', 'Peach___Bacterial_spot', 'Peach___healthy', 'Pepper,_bell___Bacterial_spot', 'Pepper,_bell___healthy', 'Potato___Early_blight', 'Potato___Late_blight', 'Potato___healthy', 'Raspberry___healthy', 'Soybean___healthy', 'Squash___Powdery_mildew', 'Strawberry___Leaf_scorch', 'Strawberry___healthy', 'Tomato___Bacterial_spot', 'Tomato___Early_blight', 'Tomato___Late_blight', 'Tomato___Leaf_Mold', 'Tomato___Septoria_leaf_spot', 'Tomato___Spider_mites Two-spotted_spider_mite', 'Tomato___Target_Spot', 'Tomato___Tomato_Yellow_Leaf_Curl_Virus', 'Tomato___Tomato_mosaic_virus', 'Tomato___healthy']\n"
     ]
    }
   ],
   "source": [
    "image_datasets = datasets.ImageFolder(root=data_dir)\n",
    "class_names = image_datasets.classes\n",
    "print(f'Number of Classes: {len(class_names)}\\nData set class names: \\n{class_names}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of train: 43445 | No of val: 5430 | No of test: 5430 | \n"
     ]
    }
   ],
   "source": [
    "train, val, test = torch.utils.data.random_split(image_datasets, [0.8, 0.1, 0.1])\n",
    "print(f'No of train: {len(train)} | No of val: {len(val)} | No of test: {len(test)} | ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor()\n",
    "class PlantVillageDataset(Dataset):\n",
    "\tdef __init__(self, datasets, transform=None):\n",
    "\t\tself.dataset = datasets\n",
    "\t\tself.transform = transform\n",
    "\t\t\n",
    "\tdef __getitem__(self, index):\n",
    "\t\tif self.transform:\n",
    "\t\t\tx = self.transform(self.dataset[index][0])\n",
    "\t\telse:\n",
    "\t\t\tx = self.dataset[index][0]\n",
    "\t\ty = self.dataset[index][1]\n",
    "\t\treturn x, y\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(ConvNet, self).__init__()\n",
    "\t\tself.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5)\n",
    "\t\tself.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\t\tself.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "\t\tself.fc1 = nn.Linear(59536, 120)   # (n + 2p -f)/s + 1\n",
    "\t\tself.fc2 = nn.Linear(120, 84)        \n",
    "\t\tself.fc3 = nn.Linear(84, 38)    \n",
    "\t\t\t\n",
    "\tdef forward(self, x):\n",
    "\t\tout = self.pool(F.relu(self.conv1(x)))\n",
    "\t\tout = self.pool(F.relu(self.conv2(out)))\n",
    "\t\tout = out.view(-1, 59536)\n",
    "\t\tout = F.relu(self.fc1(out))\n",
    "\t\tout = F.relu(self.fc2(out))\n",
    "\t\tout = self.fc3(out)\n",
    "\t\treturn out\n",
    "\t\n",
    "model = ConvNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.6275, 0.6275, 0.6235,  ..., 0.4941, 0.5059, 0.5216],\n",
       "          [0.6118, 0.6118, 0.6118,  ..., 0.5020, 0.4980, 0.5098],\n",
       "          [0.6078, 0.6078, 0.6078,  ..., 0.5020, 0.4980, 0.5137],\n",
       "          ...,\n",
       "          [0.5608, 0.5608, 0.5569,  ..., 0.3490, 0.3608, 0.3608],\n",
       "          [0.5569, 0.5569, 0.5529,  ..., 0.3490, 0.3529, 0.3490],\n",
       "          [0.5529, 0.5529, 0.5490,  ..., 0.3333, 0.3373, 0.3255]],\n",
       " \n",
       "         [[0.6314, 0.6314, 0.6275,  ..., 0.4745, 0.4863, 0.5020],\n",
       "          [0.6157, 0.6157, 0.6157,  ..., 0.4824, 0.4784, 0.4902],\n",
       "          [0.6118, 0.6118, 0.6118,  ..., 0.4824, 0.4784, 0.4941],\n",
       "          ...,\n",
       "          [0.5765, 0.5765, 0.5725,  ..., 0.3412, 0.3529, 0.3529],\n",
       "          [0.5725, 0.5725, 0.5686,  ..., 0.3412, 0.3451, 0.3412],\n",
       "          [0.5686, 0.5686, 0.5647,  ..., 0.3255, 0.3294, 0.3176]],\n",
       " \n",
       "         [[0.6392, 0.6392, 0.6353,  ..., 0.4980, 0.5098, 0.5255],\n",
       "          [0.6235, 0.6235, 0.6235,  ..., 0.5059, 0.5020, 0.5137],\n",
       "          [0.6196, 0.6196, 0.6196,  ..., 0.5059, 0.5020, 0.5176],\n",
       "          ...,\n",
       "          [0.5804, 0.5804, 0.5765,  ..., 0.3529, 0.3647, 0.3647],\n",
       "          [0.5765, 0.5765, 0.5725,  ..., 0.3608, 0.3647, 0.3608],\n",
       "          [0.5725, 0.5725, 0.5686,  ..., 0.3451, 0.3490, 0.3373]]]),\n",
       " 16)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = PlantVillageDataset(train, transform)\n",
    "val_data = PlantVillageDataset(val)\n",
    "test_data = PlantVillageDataset(test)\n",
    "# for i in range(6):\n",
    "#     plt.subplot(2,3, i+1)\n",
    "#     plt.imshow(train_data[i][0], cmap='grey')\n",
    "#     print(f'{i} is class {train_data[i][1]}')\n",
    "# plt.show()\n",
    "x, y = train_data[0]\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters\n",
    "n_input_size = 256*256*3\n",
    "n_hidden_size = 10\n",
    "n_classes = 38\n",
    "n_epochs = 1\n",
    "batch_size = 1\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_data_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "test_data_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "# # for i in range(1):\n",
    "# x = iter(train_data_loader)\n",
    "# next(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "ConvNet                                  --\n",
      "├─Conv2d: 1-1                            456\n",
      "├─MaxPool2d: 1-2                         --\n",
      "├─Conv2d: 1-3                            2,416\n",
      "├─Linear: 1-4                            7,144,440\n",
      "├─Linear: 1-5                            10,164\n",
      "├─Linear: 1-6                            3,230\n",
      "=================================================================\n",
      "Total params: 7,160,706\n",
      "Trainable params: 7,160,706\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "print(summary(model, batch_dim=batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ==============================\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "start_time = time.time()\n",
    "n_total_steps = len(train_data_loader)\n",
    "losses = []\n",
    "print(f'\\n {\"=\"*30}')\n",
    "for epoch in range(n_epochs):\n",
    "    for i, (images, labels) in enumerate(train_data_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        #forward\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        #backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    # if(epoch + 1) % 10 == 0:\n",
    "    losses.append(loss.item())\n",
    "    print(f'| Epoch: {epoch+1}/{n_epochs}\\t| Loss: {loss.item():.4f} |')\n",
    "print(f' {\"=\"*30}\\n')\n",
    "end_time = time.time() - start_time\n",
    "#test\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_data_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        n_samples += labels.shape[0]\n",
    "        n_correct += (predictions == labels).sum().item()\n",
    "    accuracy = n_correct * 100.0 / n_samples\n",
    "    print(f'\\tAccuracy: {accuracy:.2f}%')\n",
    "print(f'\\n {\"=\"*30}\\n')\n",
    "print(f'  Training Time: {end_time/60:.2f} Minute(s)')\n",
    "print(f'\\n {\"=\"*30}\\n')\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML-AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
